# -*- coding: utf-8 -*-
"""
Created on Thu Feb 26 13:14:17 2015

@author: chenj
"""
import os, gzip
import numpy as np
from itertools import izip
from csv import reader, writer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import log_loss, confusion_matrix
from sklearn.cross_validation import KFold


# Set path to your consolidated files
path = os.path.dirname(os.path.realpath(__file__))
os.chdir(path)

# File names
ftrain  = 'train_feature.csv'
ftest   = 'test_feature.csv'
flabel  = 'trainLabels.csv'
fsubmission = 'submission.csv'

# Parameters for Randomforest
ntree = 200
verbose = 0

# Dimensions for train and test set
ntrain     = 10868
ntrfeature = 16**2 + 1 + 1   # For two_byte_codes, filesize, label
ntest      = 10873
nfeature   = 16**2 + 1       # For two_byte_codes, filesize

# control parameters
run_test = False
run_submission = False

read_mode, write_mode = ('rb','wb')
    
############################
## Utility functions      ##
############################  

def CrossValidation(X, y, clf):
    # Construct a kfolds object
    kf = KFold(len(y), n_folds=10, shuffle=True)
    y_prob = np.zeros((len(y), 9))
    y_pred = np.zeros(len(y))
    
    # Iterate through folds
    for train_index, test_index in kf:
        X_train, X_test = X[train_index], X[test_index]
        y_train = y[train_index]

        clf.fit(X_train, y_train)
        y_prob[test_index] = clf.predict_proba(X_test)
        y_pred[test_index] = clf.predict(X_test)
    
    return y_prob, y_pred
        

def GetCVResult(y_true, y_prob, y_pred):
    ''' get the cross validation result on the model performance
    '''
    print 'logloss is: %.3f' % log_loss(y_true, y_prob)
    print 'confusion matrix of training data:'
    print confusion_matrix(y_true, y_pred)


############################
##  Training              ##
############################

print('loading training set...')

train = np.zeros((ntrain, ntrfeature), dtype = int)
with open(ftrain, read_mode) as f:
    next(f)   
    for t,row in enumerate(reader(f)):
        train[t,:-1] = map(int, row[1:])
        if(t+1)%1000==0:
            print(t+1, 'records loaded')
            
with open(flabel, read_mode) as fl:    
    next(fl)
    for t, row in enumerate(reader(fl)):
        train[t,-1] = int(row[1])            
  
clf = RandomForestClassifier(n_estimators = ntree, verbose = verbose)

# Start training
print('Start 10-fold cross validation...')
y_prob, y_pred = CrossValidation(train[:,:-1], train[:,-1], clf)
y_true = train[:, -1].tolist()
print('the CV results are:')
GetCVResult(y_true, y_prob, y_pred)

# after CV, train on the entire training data
clf.fit(train[:,:-1], train[:,-1])
del train

#################################
## Predict for whole test set  ##
#################################

if run_test == True:
    # set up test data
    test = np.zeros((ntest, nfeature), dtype = int)
    Ids = []    # Required test set ids
    
    print('loading test data ...')
    
    with open(ftest, read_mode) as f:
        next(f)    # Ignoring header
        for t,row in enumerate(reader(f)):
            test[t,:] = map(int, row[1:])
            Ids.append(row[0])
            if (t+1) % 1000 == 0:
                print(t+1, 'records loaded')
    
    print('making prediction on test data')
    y_pred = clf.predict_proba(test)

##############################
## create submission file   ##
##############################
if run_submission:
    print 'generating submission file ...'
    
    with gzip.open(fsubmission, write_mode) as f:
        fw = writer(f)
        header = ['Id'] + ['Prediction' + str(i) for i in range(1,10)]
        fw.writerow(header)
    
        for t, (Id, pred) in enumerate(izip(Ids, y_pred.tolist())):
            fw.writerow([Id]+pred)
            if (t+1) % 1000 == 0:
                print(t+1, 'prediction written')
            
